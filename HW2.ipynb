{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRBhMZtdf94"
      },
      "source": [
        "# Download dataset with Pytorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ссылка на colab: https://colab.research.google.com/drive/1mlK9gf7zlicoohEeLfbo_uTcT0vFGFC6?usp=sharing"
      ],
      "metadata": {
        "id": "-mVy4WBHVHOg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNE5Qqw_rdsV"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKAZ-aQtrg8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1626e7a5-d661-4e74-9182-027a5641e024"
      },
      "source": [
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "transform  = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Define transformation for each image\n",
        "# transform  = transforms.Compose([\n",
        "#    transforms.Lambda(lambda x: np.array(x).flatten()), #Stretch image into row [32,32,3] -> [3072]\n",
        "#])\n",
        "\n",
        "# Download a CIFAR10 dataset\n",
        "dataset = datasets.CIFAR10(\"content\",\n",
        "                           train=True,\n",
        "                           transform = transform,\n",
        "                           download=True)\n",
        "\n",
        "dataset.transform = transforms.Lambda(lambda x: np.array(x).flatten());"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3F4IoDErlcw"
      },
      "source": [
        "## Split dataset & define dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu02DmABYxoh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "32fb064a-264b-4f21-e0cd-774aeb123a5e"
      },
      "source": [
        "train_ds, val_ds, _ = random_split(dataset, [20000, 1000, 29000])\n",
        "# random_split(dataset, [2000, 100, 47900])\n",
        "# Hint: Perform debug on smaller subset\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size = batch_size)\n",
        "val_loader = DataLoader(val_ds, batch_size = batch_size)\n",
        "\n",
        "# Display one image\n",
        "for images, class_nums in train_loader:\n",
        "  print (images.shape, class_nums.shape) # class_nums are tensor!\n",
        "  display(Image.fromarray(images[0].reshape((32,32,3)).numpy()), class_nums[0].item()) \n",
        "  break "
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 3072]) torch.Size([256])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F6D458FB250>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqC6xXhSeUPr"
      },
      "source": [
        "# Implement LinearClassifier class for CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaxIJUM7eQUp"
      },
      "source": [
        "import random\n",
        "\n",
        "class LinearClassifier:\n",
        "  def __init__(self, labels):\n",
        "    self.labels = labels\n",
        "    self.classes_num = len(labels)\n",
        "    # Generate a random weight matrix of small numbers\n",
        "    self.W = np.random.randn(3073, self.classes_num) * 0.0001 \n",
        "    self.batch_size = 256\n",
        "\n",
        "  \n",
        "  def train(self, x_train, y_train, learning_rate = 1e-8):\n",
        "    \"\"\"\n",
        "      Arguments:\n",
        "        x  (numpy.array): collection of objects (batch)\n",
        "        y  (numpy.array): collection of integer \n",
        "        representing a class number for objects from x\n",
        "    \n",
        "    \"\"\"\n",
        "    loss = 0.0\n",
        "    len = x_train.shape[0]\n",
        "    indexes = list(range(len))\n",
        "    random.shuffle(indexes)\n",
        "\n",
        "    for i in range(0, len, self.batch_size):\n",
        "        idx = indexes[i:i + self.batch_size]\n",
        "        x_batch = x_train[idx]\n",
        "        y_batch = y_train[idx]\n",
        "        # Bias trick\n",
        "        x_batch = np.hstack([x_batch, np.ones((x_batch.shape[0], 1))])      # batch 256x3073 \n",
        "        loss_val, grad = self.loss(x_batch, y_batch)\n",
        "        loss += loss_val\n",
        "        self.W -= learning_rate * grad # Weight updating\n",
        "    \n",
        "\n",
        "    return loss/x_batch.shape[0]\n",
        "\n",
        "  def loss(self, x, y): # x and y are batches\n",
        "    \"\"\"\n",
        "      Arguments:\n",
        "        x  (numpy.array): collection of objects (batch)\n",
        "        y  (numpy.array): collection of integer \n",
        "        representing a class number for objects from x\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    loss = 0.0\n",
        "    dW = np.zeros(self.W.shape)\n",
        "    current = x.shape[0]\n",
        "    for i in range(current): \n",
        "      scores = x[i].dot(self.W)               # 1x3073 x 3073x10\n",
        "      class_score = scores[int(y[i])]\n",
        "      zero_loss_count = 0\n",
        "      for j in range(self.classes_num):\n",
        "          if j == y[i]: \n",
        "              continue\n",
        "          margin = scores[j] - class_score + 1\n",
        "          if margin > 0:\n",
        "              zero_loss_count += 1\n",
        "              loss += margin\n",
        "              dW[:, j] += x[i]\n",
        "      dW[:, int(y[i])] -= zero_loss_count * x[i]   \n",
        "    loss /= current\n",
        "    dW /= current\n",
        "    return loss, dW\n",
        "      \n",
        "  def predict(self,x):\n",
        "    x = np.hstack([x, np.ones((x.shape[0], 1))]) \n",
        "    scores = x.dot(self.W)                    # (256, 3073) * (3073, 10)\n",
        "    return np.argmax(scores, axis = 1)\n"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyVPgrr5xjhU"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5zVN1kHd43W"
      },
      "source": [
        "## Function for accuracy checking\n",
        "\n",
        "Don't change this code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzhRClCsdzJw"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def validate(model, dataloader):\n",
        "  y_predicted = np.array([])\n",
        "  y_gtrue = np.array([])\n",
        "  for images, class_nums in dataloader:\n",
        "    index = model.predict(images.numpy())\n",
        "    y_predicted = np.append(y_predicted,index) \n",
        "    y_gtrue = np.append(y_gtrue,class_nums.numpy()) \n",
        "  return accuracy_score(y_gtrue, y_predicted)  "
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQr1qYUlxq7X"
      },
      "source": [
        "## Train loop\n",
        "Let's train our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phcDEj7OdpGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d6283d2-be81-4b63-cd62-8750dc489865"
      },
      "source": [
        "# Best: 0.419, time ~ 7 минут\n",
        "model = LinearClassifier(dataset.classes)\n",
        "best_accuracy = 0\n",
        "for epoch in range(25):\n",
        "  for images, class_nums in train_loader:\n",
        "    loss = model.train(images.numpy(), class_nums.numpy())\n",
        "    accuracy = validate(model,val_loader)\n",
        "  if best_accuracy < accuracy:\n",
        "     best_accuracy = accuracy\n",
        "  print(f\"Epoch {epoch} Loss: {loss}, Accuracy:{accuracy}\")\n",
        "\n",
        "print(f\"Best accuracy is {best_accuracy}\")"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Loss: 0.224326151007772, Accuracy:0.227\n",
            "Epoch 1 Loss: 0.195974531715777, Accuracy:0.291\n",
            "Epoch 2 Loss: 0.18197397257508868, Accuracy:0.318\n",
            "Epoch 3 Loss: 0.17317501173666272, Accuracy:0.334\n",
            "Epoch 4 Loss: 0.16615502041020933, Accuracy:0.352\n",
            "Epoch 5 Loss: 0.1611404387394766, Accuracy:0.368\n",
            "Epoch 6 Loss: 0.15697845235187588, Accuracy:0.365\n",
            "Epoch 7 Loss: 0.15302931858113752, Accuracy:0.377\n",
            "Epoch 8 Loss: 0.1494314274912509, Accuracy:0.387\n",
            "Epoch 9 Loss: 0.14653940046898178, Accuracy:0.391\n",
            "Epoch 10 Loss: 0.14384340593964023, Accuracy:0.4\n",
            "Epoch 11 Loss: 0.14091659449744, Accuracy:0.4\n",
            "Epoch 12 Loss: 0.13877883928586665, Accuracy:0.4\n",
            "Epoch 13 Loss: 0.13636695263164605, Accuracy:0.404\n",
            "Epoch 14 Loss: 0.1342034740727454, Accuracy:0.41\n",
            "Epoch 15 Loss: 0.1319627419521889, Accuracy:0.412\n",
            "Epoch 16 Loss: 0.1300063354490379, Accuracy:0.412\n",
            "Epoch 17 Loss: 0.1279150593092953, Accuracy:0.417\n",
            "Epoch 18 Loss: 0.1261872729716475, Accuracy:0.419\n",
            "Epoch 19 Loss: 0.12441478911881278, Accuracy:0.417\n",
            "Epoch 20 Loss: 0.1227454146491978, Accuracy:0.416\n",
            "Epoch 21 Loss: 0.12122065531784745, Accuracy:0.419\n",
            "Epoch 22 Loss: 0.1197906241976198, Accuracy:0.417\n",
            "Epoch 23 Loss: 0.11845776009089179, Accuracy:0.416\n",
            "Epoch 24 Loss: 0.11709063194257854, Accuracy:0.416\n",
            "Best accuracy is 0.419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4tIFR5bwZFi"
      },
      "source": [
        "# Check model on test dataset\n",
        "\n",
        "You must get accuracy above 0.35\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM0pWYJlwibm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59f15f6e-ecec-4678-db2a-945c2346c178"
      },
      "source": [
        "# 0.3531))\n",
        "test_dataset = datasets.CIFAR10(\"content\",\n",
        "                           train=False,\n",
        "                           transform = transforms.Lambda(lambda x: np.array(x).flatten()), # Transforms stay the same\n",
        "                           download=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size = batch_size)\n",
        "\n",
        "accuracy = validate(model,test_loader)\n",
        "print(f\"Accuracy on test:{accuracy}\")\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Accuracy on test:0.3531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsImxpggG8bH"
      },
      "source": [
        "# Place for brief conclusion\n",
        "Feel free to describe troubles here.\n",
        "\n",
        "Было немного легче, чем в прошлый раз (был экскурс в работу с изображениями, сам линейный классификатор + лайфак с переводом в строку)\n",
        "\n",
        "Трудность - размерности, пришлось за ними очень внимательно следить\n",
        "\n",
        "В остальном было вроде бы не сложно)\n",
        "\n",
        "PS Кажется странным, что кросс-валидация и различные улучшения показали более худший результат. Возможно, это связано с рандомностью деления массива изображений.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ13OmfCEb1w"
      },
      "source": [
        "# Ideas for extra work\n",
        "\n",
        "- Implenment CrossEntropyLoss function\n",
        "- Implement bias trick\n",
        "- Add regularization to SVM loss\n",
        "- Find best learning rate and regularization strength using Cross-Validation\n",
        "- Normalize data\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bias trick in LinearClassifier, нормализация в самом начале"
      ],
      "metadata": {
        "id": "lUOmPRjsIY0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-entropy + regularization\n",
        "\n",
        "class LinearClassifierBest(LinearClassifier):\n",
        "    def __init__(self, labels, reg_strength):\n",
        "      super().__init__(labels)\n",
        "      self.reg = reg_strength\n",
        "\n",
        "    def loss(self, x, y):\n",
        "      samples = x.shape[0]\n",
        "\n",
        "      # Cross-entropy\n",
        "      \n",
        "      scores = x.dot(self.W)                              # 256x10\n",
        "      max_scores = scores.max(axis = 1, keepdims = True)  # normalize\n",
        "      scores -= max_scores\n",
        "      correct = np.array([scores[i][int(y[i])] for i in range(samples)])\n",
        "      \n",
        "      # Softmax\n",
        "      \n",
        "      loss = - correct.sum() + max_scores.sum() + np.log(np.exp(scores).sum(axis=1)).sum()\n",
        "      loss /= samples\n",
        "      loss += self.reg * np.sum(self.W * self.W)\n",
        "      \n",
        "      probs = (np.exp(scores) / np.exp(scores).sum(axis=1).reshape(-1, 1))\n",
        "      dW = np.zeros(x.shape)\n",
        "      \n",
        "      # Gradient + regularization\n",
        "      \n",
        "      probs[np.arange(samples), y] -= 1\n",
        "      probs /= samples\n",
        "      dW = x.T.dot(probs)\n",
        "      dW += 2 * self.reg * self.W\n",
        "      return loss, dW"
      ],
      "metadata": {
        "id": "c81yruOfIYCJ"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best: 0.355, time ~ 6 минут\n",
        "model = LinearClassifierBest(dataset.classes, 1000)\n",
        "best_accuracy = 0\n",
        "for epoch in range(25):\n",
        "  for images, class_nums in train_loader:\n",
        "    loss = model.train(images.numpy(), class_nums.numpy())\n",
        "    accuracy = validate(model,val_loader)\n",
        "  if best_accuracy < accuracy:\n",
        "     best_accuracy = accuracy\n",
        "  print(f\"Epoch {epoch} Loss: {loss}, Accuracy:{accuracy}\")\n",
        "\n",
        "print(f\"Best accuracy is {best_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVwqj3UPKgV8",
        "outputId": "487abce7-c6d2-463d-cfe1-c458704ef56f"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Loss: 0.09554415435366541, Accuracy:0.165\n",
            "Epoch 1 Loss: 0.09480721553941943, Accuracy:0.208\n",
            "Epoch 2 Loss: 0.09463187682642801, Accuracy:0.224\n",
            "Epoch 3 Loss: 0.09472647846638352, Accuracy:0.243\n",
            "Epoch 4 Loss: 0.09498441623164229, Accuracy:0.256\n",
            "Epoch 5 Loss: 0.09540485382518878, Accuracy:0.267\n",
            "Epoch 6 Loss: 0.09600720180504471, Accuracy:0.273\n",
            "Epoch 7 Loss: 0.09664277211459632, Accuracy:0.277\n",
            "Epoch 8 Loss: 0.09725016878247929, Accuracy:0.277\n",
            "Epoch 9 Loss: 0.09783495377770274, Accuracy:0.284\n",
            "Epoch 10 Loss: 0.09841087794358125, Accuracy:0.295\n",
            "Epoch 11 Loss: 0.09895182277680326, Accuracy:0.301\n",
            "Epoch 12 Loss: 0.09945977709203865, Accuracy:0.304\n",
            "Epoch 13 Loss: 0.09995415431147572, Accuracy:0.31\n",
            "Epoch 14 Loss: 0.10042930709072335, Accuracy:0.312\n",
            "Epoch 15 Loss: 0.10087536499834329, Accuracy:0.319\n",
            "Epoch 16 Loss: 0.10129837625996609, Accuracy:0.321\n",
            "Epoch 17 Loss: 0.10169958460997446, Accuracy:0.328\n",
            "Epoch 18 Loss: 0.10207697460820632, Accuracy:0.335\n",
            "Epoch 19 Loss: 0.10243888886613405, Accuracy:0.338\n",
            "Epoch 20 Loss: 0.10278825598916194, Accuracy:0.341\n",
            "Epoch 21 Loss: 0.10311748295266968, Accuracy:0.344\n",
            "Epoch 22 Loss: 0.10342786043428648, Accuracy:0.347\n",
            "Epoch 23 Loss: 0.10372058846736461, Accuracy:0.352\n",
            "Epoch 24 Loss: 0.10399684134258173, Accuracy:0.355\n",
            "Best accuracy is 0.355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0.3016\n",
        "test_dataset = datasets.CIFAR10(\"content\",\n",
        "                           train=False,\n",
        "                           transform = transforms.Lambda(lambda x: np.array(x).flatten()), # Transforms stay the same\n",
        "                           download=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size = batch_size)\n",
        "accuracy = validate(model, test_loader)\n",
        "print(f\"Accuracy on test:{accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTlw_XQhKgoU",
        "outputId": "a190d779-326e-4775-9f50-08a81eca79cb"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Accuracy on test:0.3016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation\n",
        "# 0.418; 1000; 1e-06\n",
        "\n",
        "learning_rates = [1e-8, 1e-7, 1e-6]\n",
        "regularization_strengths = [1e3, 1e4, 1e5]\n",
        "best_val, best_lr, best_reg = 0, 0, 0\n",
        "for lr in learning_rates:\n",
        "   for reg in regularization_strengths:\n",
        "       model = LinearClassifierBest(dataset.classes, reg)\n",
        "       best_accuracy = 0\n",
        "       for epoch in range(25):\n",
        "         for images, class_nums in train_loader:\n",
        "           loss = model.train(images.numpy(), class_nums.numpy(), lr)\n",
        "           accuracy = validate(model, val_loader)\n",
        "         if best_accuracy < accuracy:\n",
        "           best_accuracy = accuracy\n",
        "       if best_accuracy > best_val:\n",
        "           best_val, best_lr, best_reg = best_accuracy, lr, reg\n",
        " \n",
        "print(f'best validation accuracy: {best_val}, reg: {best_reg}, lr:{lr}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRHxh9ItytkG",
        "outputId": "61870e3b-a153-4d14-c856-dd75e81365f9"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best validation accuracy: 0.418, reg: 1000.0, lr:1e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best: 0.273, time ~ 5 минут\n",
        "model = LinearClassifierBest(dataset.classes, 1000)\n",
        "best_accuracy = 0\n",
        "for epoch in range(25):\n",
        "  for images, class_nums in train_loader:\n",
        "    loss = model.train(images.numpy(), class_nums.numpy(), 1e-6)\n",
        "    accuracy = validate(model,val_loader)\n",
        "  if best_accuracy < accuracy:\n",
        "     best_accuracy = accuracy\n",
        "  print(f\"Epoch {epoch} Loss: {loss}, Accuracy:{accuracy}\")\n",
        "\n",
        "print(f\"Best accuracy is {best_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqXuOiXUQ2ob",
        "outputId": "c6b2c035-7f06-42c8-f6cc-b7d331d256fb"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Loss: 0.3499342990004101, Accuracy:0.171\n",
            "Epoch 1 Loss: 0.24778673259396075, Accuracy:0.165\n",
            "Epoch 2 Loss: 0.2703957870295536, Accuracy:0.158\n",
            "Epoch 3 Loss: 0.2934189736529044, Accuracy:0.169\n",
            "Epoch 4 Loss: 0.4883417526425824, Accuracy:0.273\n",
            "Epoch 5 Loss: 0.21376860998853142, Accuracy:0.242\n",
            "Epoch 6 Loss: 0.33844728005316227, Accuracy:0.2\n",
            "Epoch 7 Loss: 0.22490356774799997, Accuracy:0.25\n",
            "Epoch 8 Loss: 0.3061649951775279, Accuracy:0.228\n",
            "Epoch 9 Loss: 0.3509980929742641, Accuracy:0.21\n",
            "Epoch 10 Loss: 0.3081530925125234, Accuracy:0.168\n",
            "Epoch 11 Loss: 0.36053291175253477, Accuracy:0.171\n",
            "Epoch 12 Loss: 0.3475450319340551, Accuracy:0.209\n",
            "Epoch 13 Loss: 0.3445659408436043, Accuracy:0.178\n",
            "Epoch 14 Loss: 0.3153483826022762, Accuracy:0.206\n",
            "Epoch 15 Loss: 0.4496636545423745, Accuracy:0.15\n",
            "Epoch 16 Loss: 0.2720235819145431, Accuracy:0.214\n",
            "Epoch 17 Loss: 0.3907281430781828, Accuracy:0.135\n",
            "Epoch 18 Loss: 0.22755875761034144, Accuracy:0.158\n",
            "Epoch 19 Loss: 0.35967240867208855, Accuracy:0.174\n",
            "Epoch 20 Loss: 0.214277714945417, Accuracy:0.186\n",
            "Epoch 21 Loss: 0.31398950738847997, Accuracy:0.155\n",
            "Epoch 22 Loss: 0.3222526827695392, Accuracy:0.119\n",
            "Epoch 23 Loss: 0.3750738823394714, Accuracy:0.129\n",
            "Epoch 24 Loss: 0.3979755920255369, Accuracy:0.192\n",
            "Best accuracy is 0.273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0.1741\n",
        "test_dataset = datasets.CIFAR10(\"content\",\n",
        "                           train=False,\n",
        "                           transform = transforms.Lambda(lambda x: np.array(x).flatten()), # Transforms stay the same\n",
        "                           download=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size = batch_size)\n",
        "accuracy = validate(model, test_loader)\n",
        "print(f\"Accuracy on test:{accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t61rErnTQnr4",
        "outputId": "604511fd-aa3f-47d8-bcaa-50c98e1b17eb"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Accuracy on test:0.1741\n"
          ]
        }
      ]
    }
  ]
}